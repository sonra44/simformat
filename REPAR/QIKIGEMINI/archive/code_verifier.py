"""
–≠—Ç–∞–ª–æ–Ω–Ω—ã–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞.
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞.
"""

import os
import ast
import sys
import json
import traceback
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict, Counter

try:
    from project_schema import (
        MODULE_REQUIREMENTS,
        CONFIG_USAGE_REQUIREMENTS,
        ARCHITECTURE_RULES,
        VALIDATION_EXCEPTIONS,
        ImportType,
        ComponentType,
        # –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
        EXPECTED_IMPORTS,
        EXPECTED_COMPONENTS,
        EXPECTED_CONFIG_USAGE,
    )
except ImportError:
    print("Warning: Could not import from project_schema. Using fallback mode.")
    EXPECTED_IMPORTS = {}
    EXPECTED_COMPONENTS = {}
    EXPECTED_CONFIG_USAGE = {}


class SeverityLevel(Enum):
    """–£—Ä–æ–≤–Ω–∏ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –ø—Ä–æ–±–ª–µ–º."""

    CRITICAL = "CRITICAL"
    ERROR = "ERROR"
    WARNING = "WARNING"
    INFO = "INFO"
    STYLE = "STYLE"


@dataclass
class Issue:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ –∫–æ–¥–µ."""

    file_path: str
    line_number: Optional[int] = None
    column: Optional[int] = None
    severity: SeverityLevel = SeverityLevel.ERROR
    category: str = "General"
    code: str = "E001"
    message: str = ""
    suggestion: Optional[str] = None
    context: Optional[str] = None

    def __str__(self) -> str:
        location = f"{self.file_path}"
        if self.line_number:
            location += f":{self.line_number}"
            if self.column:
                location += f":{self.column}"

        result = f"[{self.severity.value}] {location} - {self.category}({self.code}): {self.message}"
        if self.suggestion:
            result += f"\n  Suggestion: {self.suggestion}"
        return result


@dataclass
class FileAnalysis:
    """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""

    file_path: str
    imports: Set[str] = field(default_factory=set)
    classes: Dict[str, List[str]] = field(default_factory=dict)
    functions: Set[str] = field(default_factory=set)
    config_usages: Set[str] = field(default_factory=set)
    lines_of_code: int = 0
    cyclomatic_complexity: int = 0
    docstring_coverage: float = 0.0
    issues: List[Issue] = field(default_factory=list)


class EtalonniyCodeVerifier:
    """
    –≠—Ç–∞–ª–æ–Ω–Ω—ã–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–æ–¥–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –∞–Ω–∞–ª–∏–∑–∞.
    """

    def __init__(self, project_root: str = ".", config_file: Optional[str] = None):
        self.project_root = Path(project_root).resolve()
        self.config = self._load_config(config_file)
        self.all_issues: List[Issue] = []
        self.file_analyses: Dict[str, FileAnalysis] = {}

        # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats = {
            "files_processed": 0,
            "total_lines": 0,
            "issues_by_severity": Counter(),
            "issues_by_category": Counter(),
        }

        # –¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
        self.colors = {
            "CRITICAL": "\033[1;31m",  # –Ø—Ä–∫–æ-–∫—Ä–∞—Å–Ω—ã–π
            "ERROR": "\033[0;31m",  # –ö—Ä–∞—Å–Ω—ã–π
            "WARNING": "\033[0;33m",  # –ñ–µ–ª—Ç—ã–π
            "INFO": "\033[0;36m",  # Cyan
            "STYLE": "\033[0;35m",  # –ü—É—Ä–ø—É—Ä–Ω—ã–π
            "SUCCESS": "\033[0;32m",  # –ó–µ–ª–µ–Ω—ã–π
            "RESET": "\033[0m",  # –°–±—Ä–æ—Å —Ü–≤–µ—Ç–∞
            "BOLD": "\033[1m",  # –ñ–∏—Ä–Ω—ã–π
        }

    def _load_config(self, config_file: Optional[str]) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞."""
        default_config = {
            "ignore_patterns": [
                "__pycache__",
                ".git",
                ".pytest_cache",
                "venv",
                ".venv",
                "*.pyc",
            ],
            "max_line_length": 100,
            "enforce_docstrings": True,
            "check_type_hints": True,
            "check_complexity": True,
            "max_complexity": 10,
            "detailed_reports": True,
            "colorized_output": True,
        }

        if config_file and Path(config_file).exists():
            try:
                with open(config_file, "r", encoding="utf-8") as f:
                    user_config = json.load(f)
                default_config.update(user_config)
            except Exception as e:
                self._print_warning(f"Could not load config file {config_file}: {e}")

        return default_config

    def _colorize(self, text: str, color_key: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ü–≤–µ—Ç–æ–≤–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∫ —Ç–µ–∫—Å—Ç—É."""
        if not self.config.get("colorized_output", True):
            return text
        return f"{self.colors.get(color_key, '')}{text}{self.colors['RESET']}"

    def _print_header(self, text: str):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ–º."""
        separator = "=" * len(text)
        print(self._colorize(f"\n{separator}", "BOLD"))
        print(self._colorize(text, "BOLD"))
        print(self._colorize(separator, "BOLD"))

    def _print_success(self, text: str):
        """–ü–µ—á–∞—Ç–∞–µ—Ç —É—Å–ø–µ—à–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
        print(self._colorize(f"‚úì {text}", "SUCCESS"))

    def _print_warning(self, text: str):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ."""
        print(self._colorize(f"‚ö† {text}", "WARNING"))

    def _print_error(self, text: str):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –æ—à–∏–±–∫—É."""
        print(self._colorize(f"‚úó {text}", "ERROR"))

    def _get_module_name(self, filepath: Path) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –º–æ–¥—É–ª—è –∏–∑ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É."""
        try:
            relative_path = filepath.relative_to(self.project_root)
            return str(relative_path.with_suffix("")).replace(os.sep, ".")
        except ValueError:
            return filepath.stem

    def _should_ignore_file(self, filepath: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–ª–µ–¥—É–µ—Ç –ª–∏ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª."""
        path_str = str(filepath)
        for pattern in self.config["ignore_patterns"]:
            if pattern.replace("*", "") in path_str:
                return True
        return False

    def _calculate_complexity(self, node: ast.AST) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å —É–∑–ª–∞ AST."""
        complexity = 1

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, (ast.And, ast.Or)):
                complexity += 1
            elif isinstance(child, ast.ListComp):
                complexity += 1

        return complexity

    def _check_docstring_coverage(self, tree: ast.AST) -> Tuple[float, List[str]]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–∫—Ä—ã—Ç–∏–µ docstring –≤ –º–æ–¥—É–ª–µ."""
        total_items = 0
        documented_items = 0
        missing_docs = []

        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                if hasattr(node, "name") and not node.name.startswith("_"):
                    total_items += 1
                    if ast.get_docstring(node):
                        documented_items += 1
                    else:
                        missing_docs.append(f"{type(node).__name__}: {node.name}")

        coverage = documented_items / total_items if total_items > 0 else 1.0
        return coverage, missing_docs

    def _parse_python_file(self, filepath: Path) -> FileAnalysis:
        """–ü–∞—Ä—Å–∏—Ç Python —Ñ–∞–π–ª –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑."""
        analysis = FileAnalysis(file_path=str(filepath))

        try:
            with open(filepath, "r", encoding="utf-8-sig") as f:
                content = f.read()
                lines = content.split("\n")
                analysis.lines_of_code = len(
                    [
                        line
                        for line in lines
                        if line.strip() and not line.strip().startswith("#")
                    ]
                )

            tree = ast.parse(content, filename=str(filepath))

            # –ê–Ω–∞–ª–∏–∑ –∏–º–ø–æ—Ä—Ç–æ–≤
            for node in tree.body:
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis.imports.add(
                            alias.name
                        )  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ–µ –∏–º—è –º–æ–¥—É–ª—è
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        analysis.imports.add(node.module)

            # –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–π
            for node in tree.body:
                if isinstance(node, ast.ClassDef):
                    methods = []
                    for item in node.body:
                        if isinstance(item, ast.FunctionDef):
                            methods.append(item.name)
                    analysis.classes[node.name] = methods
                elif isinstance(node, ast.FunctionDef):
                    analysis.functions.add(node.name)

            # –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Config
            for node in ast.walk(tree):
                if isinstance(node, ast.Attribute):
                    if isinstance(node.value, ast.Name) and node.value.id == "Config":
                        analysis.config_usages.add(f"config.{node.attr}")

            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            analysis.cyclomatic_complexity = self._calculate_complexity(tree)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ docstrings
            coverage, missing_docs = self._check_docstring_coverage(tree)
            analysis.docstring_coverage = coverage

            # –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞
            self._check_code_quality(analysis, lines, tree)

        except SyntaxError as e:
            analysis.issues.append(
                Issue(
                    file_path=str(filepath),
                    line_number=e.lineno,
                    column=e.offset,
                    severity=SeverityLevel.CRITICAL,
                    category="Syntax",
                    code="C001",
                    message=f"Syntax error: {e.msg}",
                    context=str(e.text).strip() if e.text else None,
                )
            )
        except Exception as e:
            analysis.issues.append(
                Issue(
                    file_path=str(filepath),
                    severity=SeverityLevel.ERROR,
                    category="Parsing",
                    code="E001",
                    message=f"Failed to parse file: {str(e)}",
                    context=traceback.format_exc(),
                )
            )

        return analysis

    def _check_code_quality(
        self, analysis: FileAnalysis, lines: List[str], tree: ast.AST
    ):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞."""
        filepath = analysis.file_path

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫
        for i, line in enumerate(lines, 1):
            if len(line) > self.config["max_line_length"]:
                analysis.issues.append(
                    Issue(
                        file_path=filepath,
                        line_number=i,
                        severity=SeverityLevel.STYLE,
                        category="Style",
                        code="S001",
                        message=f"Line too long ({len(line)} > {self.config['max_line_length']})",
                        suggestion="Consider breaking this line into multiple lines",
                    )
                )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if analysis.cyclomatic_complexity > self.config.get("max_complexity", 10):
            analysis.issues.append(
                Issue(
                    file_path=filepath,
                    severity=SeverityLevel.WARNING,
                    category="Complexity",
                    code="W002",
                    message=f"High cyclomatic complexity: {analysis.cyclomatic_complexity}",
                    suggestion="Consider refactoring into smaller functions",
                )
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ docstrings
        if self.config.get("enforce_docstrings") and analysis.docstring_coverage < 0.8:
            analysis.issues.append(
                Issue(
                    file_path=filepath,
                    severity=SeverityLevel.WARNING,
                    category="Documentation",
                    code="W003",
                    message=f"Low docstring coverage: {analysis.docstring_coverage:.1%}",
                    suggestion="Add docstrings to classes and public functions",
                )
            )

    def _verify_imports(self, module_name: str, analysis: FileAnalysis) -> List[Issue]:
        """–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∏–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª—è."""
        issues = []

        if module_name not in EXPECTED_IMPORTS:
            return issues

        expected_imports = set(EXPECTED_IMPORTS[module_name])
        actual_imports = analysis.imports

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
        missing_imports = expected_imports - actual_imports
        if missing_imports:
            issues.append(
                Issue(
                    file_path=analysis.file_path,
                    severity=SeverityLevel.ERROR,
                    category="Architecture",
                    code="E002",
                    message=f"Missing expected imports: {', '.join(sorted(missing_imports))}",
                    suggestion=f"Add imports: {', '.join(sorted(missing_imports))}",
                )
            )

        return issues

    def _verify_components(
        self, module_name: str, analysis: FileAnalysis
    ) -> List[Issue]:
        """–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–¥—É–ª—è."""
        issues = []

        if module_name not in EXPECTED_COMPONENTS:
            return issues

        expected_components = EXPECTED_COMPONENTS[module_name]

        for class_name, expected_methods in expected_components.items():
            if class_name not in analysis.classes:
                issues.append(
                    Issue(
                        file_path=analysis.file_path,
                        severity=SeverityLevel.ERROR,
                        category="Architecture",
                        code="E003",
                        message=f"Missing expected class: '{class_name}'",
                        suggestion=f"Implement class {class_name} with methods: {', '.join(expected_methods)}",
                    )
                )
            else:
                actual_methods = set(analysis.classes[class_name])
                missing_methods = set(expected_methods) - actual_methods
                if missing_methods:
                    issues.append(
                        Issue(
                            file_path=analysis.file_path,
                            severity=SeverityLevel.ERROR,
                            category="Architecture",
                            code="E004",
                            message=f"Class '{class_name}' missing methods: {', '.join(sorted(missing_methods))}",
                            suggestion=f"Add missing methods to {class_name} class",
                        )
                    )

        return issues

    def _verify_config_usage(
        self, module_name: str, analysis: FileAnalysis
    ) -> List[Issue]:
        """–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
        issues = []

        if module_name not in EXPECTED_CONFIG_USAGE:
            return issues

        expected_config = EXPECTED_CONFIG_USAGE[module_name]
        actual_config = analysis.config_usages

        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –ø–µ—á–∞—Ç—å
        # print(f"DEBUG: Verifying config for {module_name}")
        # print(f"DEBUG: expected_config type: {type(expected_config)}, value: {expected_config}")
        # print(f"DEBUG: actual_config type: {type(actual_config)}, value: {actual_config}")

        missing_config = expected_config - actual_config
        if missing_config:
            issues.append(
                Issue(
                    file_path=analysis.file_path,
                    severity=SeverityLevel.WARNING,
                    category="Configuration",
                    code="W004",
                    message=f"Missing expected Config usage: {', '.join(sorted(missing_config))}",
                    suggestion="Ensure all required configuration parameters are used",
                )
            )

        unexpected_config = actual_config - expected_config # –≠—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏—è —Ç–æ–∂–µ set - set
        if unexpected_config:
            issues.append(
                Issue(
                    file_path=analysis.file_path,
                    severity=SeverityLevel.INFO,
                    category="Configuration",
                    code="I001",
                    message=f"Unexpected Config usage: {', '.join(sorted(unexpected_config))}",
                    suggestion="Verify if these configuration parameters are necessary",
                )
            )

        return issues

    def verify_project(self) -> bool:
        """–í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç."""
        self._print_header("üîç –≠–¢–ê–õ–û–ù–ù–ê–Ø –í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø –ü–†–û–ï–ö–¢–ê")

        self.all_issues.clear()
        self.file_analyses.clear()
        self.stats = {
            "files_processed": 0,
            "total_lines": 0,
            "issues_by_severity": Counter(),
            "issues_by_category": Counter(),
        }

        # –ü–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑ Python —Ñ–∞–π–ª–æ–≤
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # –ò—Å–∫–ª—é—á–∞–µ–º –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            dirs[:] = [
                d
                for d in dirs
                if not any(
                    pattern.replace("*", "") in d
                    for pattern in self.config["ignore_patterns"]
                )
            ]

            for file in files:
                if file.endswith(".py") and file != "project_schema.py":
                    filepath = Path(root) / file
                    if not self._should_ignore_file(filepath):
                        python_files.append(filepath)

        if not python_files:
            self._print_warning("No Python files found for verification")
            return True

        print(f"Found {len(python_files)} Python files to analyze...")

        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
        for filepath in python_files:
            try:
                print(f"Analyzing: {filepath.relative_to(self.project_root)}")

                analysis = self._parse_python_file(filepath)
                module_name = self._get_module_name(filepath).split(".")[-1]

                # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                structure_issues = []
                structure_issues.extend(self._verify_imports(module_name, analysis))
                structure_issues.extend(self._verify_components(module_name, analysis))
                structure_issues.extend(
                    self._verify_config_usage(module_name, analysis)
                )

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã
                all_file_issues = analysis.issues + structure_issues

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                analysis.issues = all_file_issues
                self.file_analyses[str(filepath)] = analysis
                self.all_issues.extend(all_file_issues)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.stats["files_processed"] += 1
                self.stats["total_lines"] += analysis.lines_of_code

                for issue in all_file_issues:
                    self.stats["issues_by_severity"][issue.severity.value] += 1
                    self.stats["issues_by_category"][issue.category] += 1

            except Exception as e:
                error_issue = Issue(
                    file_path=str(filepath),
                    severity=SeverityLevel.CRITICAL,
                    category="System",
                    code="C002",
                    message=f"Failed to analyze file: {str(e)}",
                    context=traceback.format_exc(),
                )
                self.all_issues.append(error_issue)
                self.stats["issues_by_severity"]["CRITICAL"] += 1

        return (
            len(
                [
                    issue
                    for issue in self.all_issues
                    if issue.severity in [SeverityLevel.CRITICAL, SeverityLevel.ERROR]
                ]
            )
            == 0
        )

    def print_detailed_report(self):
        """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ—Ä–∫–µ."""
        self._print_header("üìä –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê")

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\n{self._colorize('–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:', 'BOLD')}")
        print(f"  –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['files_processed']}")
        print(f"  –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞: {self.stats['total_lines']}")
        print(f"  –í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º: {len(self.all_issues)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
        print(f"\n{self._colorize('–ü—Ä–æ–±–ª–µ–º—ã –ø–æ —É—Ä–æ–≤–Ω—è–º:', 'BOLD')}")
        for severity in ["CRITICAL", "ERROR", "WARNING", "INFO", "STYLE"]:
            count = self.stats["issues_by_severity"][severity]
            if count > 0:
                color_key = severity
                print(f"  {self._colorize(severity, color_key)}: {count}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if self.stats["issues_by_category"]:
            print(f"\n{self._colorize('–ü—Ä–æ–±–ª–µ–º—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:', 'BOLD')}")
            for category, count in self.stats["issues_by_category"].most_common():
                print(f"  {category}: {count}")

        # –î–µ—Ç–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º
        if self.all_issues:
            print(f"\n{self._colorize('–î–ï–¢–ê–õ–¨–ù–´–ô –°–ü–ò–°–û–ö –ü–†–û–ë–õ–ï–ú:', 'BOLD')}")
            print("-" * 80)

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
            issues_by_file = defaultdict(list)
            for issue in self.all_issues:
                issues_by_file[issue.file_path].append(issue)

            for file_path in sorted(issues_by_file.keys()):
                print(f"\n{self._colorize(f'üìÑ {file_path}', 'BOLD')}")

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã –ø–æ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –∏ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–æ–∫–∏
                severity_order = {
                    SeverityLevel.CRITICAL: 0,
                    SeverityLevel.ERROR: 1,
                    SeverityLevel.WARNING: 2,
                    SeverityLevel.INFO: 3,
                    SeverityLevel.STYLE: 4,
                }

                file_issues = sorted(
                    issues_by_file[file_path],
                    key=lambda x: (severity_order[x.severity], x.line_number or 0),
                )

                for issue in file_issues:
                    color_key = issue.severity.value
                    print(f"  {self._colorize('‚óè', color_key)} {issue}")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        self._print_improvement_suggestions()

    def _print_improvement_suggestions(self):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–æ–¥–∞."""
        print(f"\n{self._colorize('–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ:', 'BOLD')}")

        critical_count = self.stats["issues_by_severity"]["CRITICAL"]
        error_count = self.stats["issues_by_severity"]["ERROR"]
        warning_count = self.stats["issues_by_severity"]["WARNING"]

        if critical_count > 0:
            print(
                f"  üî• {self._colorize('–ö–†–ò–¢–ò–ß–ù–û', 'CRITICAL')}: –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∏—Å–ø—Ä–∞–≤—å—Ç–µ {critical_count} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º"
            )

        if error_count > 0:
            print(
                f"  ‚ùå {self._colorize('–í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢', 'ERROR')}: –ò—Å–ø—Ä–∞–≤—å—Ç–µ {error_count} –æ—à–∏–±–æ–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"
            )

        if warning_count > 0:
            print(
                f"  ‚ö†Ô∏è  {self._colorize('–°–†–ï–î–ù–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢', 'WARNING')}: –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ {warning_count} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π"
            )

        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if self.stats["issues_by_category"].get("Style", 0) > 10:
            print(
                "  üìù –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ (black, autopep8)"
            )

        if self.stats["issues_by_category"].get("Documentation", 0) > 5:
            print("  üìö –£–ª—É—á—à–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ - –¥–æ–±–∞–≤—å—Ç–µ docstrings")

        if self.stats["issues_by_category"].get("Complexity", 0) > 3:
            print("  üîÑ –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥: —É–ø—Ä–æ—Å—Ç–∏—Ç–µ —Å–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏")

    def print_summary_report(self) -> int:
        """–í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–¥ –≤—ã—Ö–æ–¥–∞."""
        self._print_header("‚ú® –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")

        total_issues = len(self.all_issues)
        critical_issues = self.stats["issues_by_severity"]["CRITICAL"]
        error_issues = self.stats["issues_by_severity"]["ERROR"]

        if total_issues == 0:
            self._print_success(
                "–û—Ç–ª–∏—á–Ω–æ! –ü—Ä–æ–±–ª–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ö–æ–¥ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —ç—Ç–∞–ª–æ–Ω—É."
            )
            self._print_success(
                f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {self.stats['files_processed']} —Ñ–∞–π–ª–æ–≤"
            )
            print("\nüèÜ " + self._colorize("–°–¢–ê–¢–£–°: –≠–¢–ê–õ–û–ù–ù–û–ï –ö–ê–ß–ï–°–¢–í–û", "SUCCESS"))
            return 0

        print(f"\n–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {total_issues}")

        if critical_issues > 0:
            self._print_error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {critical_issues}")
            print("\nüí• " + self._colorize("–°–¢–ê–¢–£–°: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò", "CRITICAL"))
            return 2

        if error_issues > 0:
            self._print_error(f"–û—à–∏–±–æ–∫: {error_issues}")
            print("\nüö® " + self._colorize("–°–¢–ê–¢–£–°: –¢–†–ï–ë–£–Æ–¢–°–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø", "ERROR"))
            return 1

        self._print_warning(
            f"–¢–æ–ª—å–∫–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ —Å—Ç–∏–ª–µ–≤—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è: {total_issues}"
        )
        print("\n‚ö†Ô∏è  " + self._colorize("–°–¢–ê–¢–£–°: –•–û–†–û–®–û, –ï–°–¢–¨ –ó–ê–ú–ï–ß–ê–ù–ò–Ø", "WARNING"))
        return 0

    def save_report(self, filename: str = "code_verification_report.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –≤ JSON —Ñ–∞–π–ª."""
        report_data = {
            "timestamp": (
                str(pd.Timestamp.now()) if "pd" in globals() else str(datetime.now())
            ),
            "project_root": str(self.project_root),
            "statistics": dict(self.stats),
            "issues": [
                {
                    "file_path": issue.file_path,
                    "line_number": issue.line_number,
                    "column": issue.column,
                    "severity": issue.severity.value,
                    "category": issue.category,
                    "code": issue.code,
                    "message": issue.message,
                    "suggestion": issue.suggestion,
                    "context": issue.context,
                }
                for issue in self.all_issues
            ],
        }

        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            self._print_success(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")
        except Exception as e:
            self._print_error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç: {e}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞."""
    import argparse

    parser = argparse.ArgumentParser(description="–≠—Ç–∞–ª–æ–Ω–Ω—ã–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞")
    parser.add_argument("--root", "-r", default=".", help="–ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞")
    parser.add_argument("--config", "-c", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    parser.add_argument("--detailed", "-d", action="store_true", help="–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç")
    parser.add_argument("--save", "-s", help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª")
    parser.add_argument(
        "--no-color", action="store_true", help="–û—Ç–∫–ª—é—á–∏—Ç—å —Ü–≤–µ—Ç–Ω–æ–π –≤—ã–≤–æ–¥"
    )

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    verifier = EtalonniyCodeVerifier(project_root=args.root, config_file=args.config)

    if args.no_color:
        verifier.config["colorized_output"] = False

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é
        success = verifier.verify_project()

        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç—ã
        if args.detailed:
            verifier.print_detailed_report()

        exit_code = verifier.print_summary_report()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if args.save:
            verifier.save_report(args.save)

        return exit_code

    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 130
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {e}")
        if args.detailed:
            traceback.print_exc()
        return 3


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
