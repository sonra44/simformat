# –ú–µ—Ç–æ–¥–∏–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –¥–ª—è —Å–∏—Å—Ç–µ–º—ã QIKI

## üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π

### 1. –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤

```python
# –ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
class NeuralNetwork:
    """
    –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
    
    –ü—Ä–∏–Ω—Ü–∏–ø—ã –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
    - –ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å: –∫–∞–∂–¥—ã–π —Å–ª–æ–π - –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    - –ì–∏–±–∫–æ—Å—Ç—å: –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
    - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è Termux
    """
    
    def __init__(self, layers, learning_rate=0.01):
        # layers: [input_size, hidden1, hidden2, ..., output_size]
        self.layers = layers
        self.learning_rate = learning_rate
        self.weights = []  # –ú–∞—Ç—Ä–∏—Ü—ã –≤–µ—Å–æ–≤ –º–µ–∂–¥—É —Å–ª–æ—è–º–∏
        self.biases = []   # –í–µ–∫—Ç–æ—Ä—ã —Å–º–µ—â–µ–Ω–∏–π
        
    # –ü—Ä–∞–≤–∏–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤: Xavier/Glorot initialization
    def _initialize_weights(self):
        """
        Xavier –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏
        """
        for i in range(len(self.layers) - 1):
            # sqrt(6 / (fan_in + fan_out))
            limit = (6 / (self.layers[i] + self.layers[i+1])) ** 0.5
            weights = np.random.uniform(-limit, limit, 
                                      (self.layers[i], self.layers[i+1]))
```

### 2. –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

```python
class ActivationFunctions:
    """
    –ö–æ–ª–ª–µ–∫—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é
    """
    
    @staticmethod
    def relu(x):
        """
        ReLU (Rectified Linear Unit)
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏, –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏: –º–æ–∂–µ—Ç "—É–º–∏—Ä–∞—Ç—å" –ø—Ä–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
        """
        return np.maximum(0, x)
    
    @staticmethod
    def leaky_relu(x, alpha=0.01):
        """
        Leaky ReLU - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è ReLU
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: –∫–æ–≥–¥–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π ReLU –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã
        –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É "–º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤"
        """
        return np.where(x > 0, x, alpha * x)
    
    @staticmethod
    def sigmoid(x):
        """
        –°–∏–≥–º–æ–∏–¥–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        –î–∏–∞–ø–∞–∑–æ–Ω: (0, 1)
        –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏: –ø—Ä–æ–±–ª–µ–º–∞ –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        """
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # –ö–ª–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    
    @staticmethod
    def tanh(x):
        """
        –ì–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–∞–Ω–≥–µ–Ω—Å
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏, –∫–æ–≥–¥–∞ –Ω—É–∂–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω (-1, 1)
        –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–æ–∫—Ä—É–≥ –Ω—É–ª—è
        """
        return np.tanh(x)
    
    @staticmethod
    def softmax(x):
        """
        Softmax –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        """
        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)
```

## üéØ –ü—Ä–∞–≤–∏–ª–∞ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤

### 1. –ü—Ä–∏–Ω—Ü–∏–ø –µ–¥–∏–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤

```python
class BaseAdvancedAgent:
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã QIKI
    
    –ü–†–ê–í–ò–õ–ê –ü–†–û–ï–ö–¢–ò–†–û–í–ê–ù–ò–Ø:
    1. –û–¥–∏–Ω –∞–≥–µ–Ω—Ç = –æ–¥–Ω–∞ –ø–æ–¥—Å–∏—Å—Ç–µ–º–∞
    2. –ß–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π
    3. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    4. –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, name, input_size, output_size):
        self.name = name
        self.neural_network = NeuralNetwork([input_size, 64, 32, output_size])
        self.knowledge_base = KnowledgeBase()
        self.performance_metrics = {
            'decisions_made': 0,
            'successful_actions': 0,
            'learning_iterations': 0,
            'average_reward': 0.0
        }
    
    def make_decision(self, state):
        """
        –ü–†–ê–í–ò–õ–û: –ö–∞–∂–¥–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ª–æ–≥–∏—Ä—É–µ–º—ã–º –∏ –æ–±—ä—è—Å–Ω–∏–º—ã–º
        """
        # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        normalized_state = self._normalize_state(state)
        
        # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        raw_output = self.neural_network.forward(normalized_state)
        
        # 3. –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        decision = self._post_process_decision(raw_output, state)
        
        # 4. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        self._log_decision(state, decision)
        
        return decision
```

### 2. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏

```python
class IntelligentPowerAgent(BaseAdvancedAgent):
    """
    –ê–≥–µ–Ω—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–æ—Å–∏—Å—Ç–µ–º–∞–º–∏
    
    –°–ü–ï–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø:
    - –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
    - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞—Ä—è–¥–∫–∏ –±–∞—Ç–∞—Ä–µ–π
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —ç–Ω–µ—Ä–≥–∏–∏
    - –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞–∑—Ä—è–¥–æ–≤
    """
    
    def __init__(self):
        super().__init__("PowerAgent", input_size=12, output_size=4)
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —ç–Ω–µ—Ä–≥–æ–∞–≥–µ–Ω—Ç–∞
        self.energy_thresholds = {
            'critical': 0.15,    # 15% - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å
            'low': 0.30,         # 30% - –Ω–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å
            'optimal': 0.80      # 80% - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
        }
        
    def _prepare_power_state(self, power_data):
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —ç–Ω–µ—Ä–≥–æ—Å–∏—Å—Ç–µ–º—ã –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        
        –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï (12 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤):
        0: –¢–µ–∫—É—â–∏–π –∑–∞—Ä—è–¥ –±–∞—Ç–∞—Ä–µ–∏ (0-1)
        1: –°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–∑—Ä—è–¥–∞ (–ê/—á)
        2: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±–∞—Ç–∞—Ä–µ–∏ (¬∞C, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
        3: –ù–∞–ø—Ä—è–∂–µ–Ω–∏–µ –±–∞—Ç–∞—Ä–µ–∏ (–í, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
        4: –ú–æ—â–Ω–æ—Å—Ç—å —Å–æ–ª–Ω–µ—á–Ω—ã—Ö –ø–∞–Ω–µ–ª–µ–π (–í—Ç, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
        5: –û–±—â–µ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã (–í—Ç, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
        6: –í—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –º–∞–Ω–µ–≤—Ä–∞ (–º–∏–Ω, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ)
        7: –ü—Ä–æ–≥–Ω–æ–∑ –æ—Å–≤–µ—â–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–ª–Ω—Ü–µ–º (0-1)
        8: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã (¬∞C, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
        9: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤ –∑–∞—Ä—è–¥–∫–∏ –±–∞—Ç–∞—Ä–µ–∏
        10: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–æ–ª–Ω–µ—á–Ω—ã—Ö –ø–∞–Ω–µ–ª–µ–π (0-1)
        11: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏ (0-1)
        """
        return [
            power_data.battery_charge,
            power_data.discharge_rate / 100.0,  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            (power_data.battery_temp + 50) / 100.0,  # –û—Ç -50 –¥–æ +50
            power_data.voltage / 50.0,
            power_data.solar_power / 1000.0,
            power_data.system_consumption / 500.0,
            power_data.time_to_maneuver / 1440.0,  # –í —Å—É—Ç–∫–∞—Ö
            power_data.sun_forecast,
            (power_data.ambient_temp + 100) / 200.0,
            power_data.charge_cycles / 10000.0,
            power_data.solar_efficiency,
            power_data.task_priority
        ]
    
    def _interpret_power_decision(self, output):
        """
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        
        –í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï (4 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞):
        0: –†–µ–∂–∏–º –∑–∞—Ä—è–¥–∫–∏ (0=–≤—ã–∫–ª, 0.5=–º–µ–¥–ª–µ–Ω–Ω–∞—è, 1=–±—ã—Å—Ç—Ä–∞—è)
        1: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏—è (0-1)
        2: –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ—â–Ω–æ—Å—Ç—å –¥–ª—è —Å–∏—Å—Ç–µ–º (0-1)
        3: –£—Ä–æ–≤–µ–Ω—å —Ç—Ä–µ–≤–æ–≥–∏ –ø–æ —ç–Ω–µ—Ä–≥–∏–∏ (0-1)
        """
        return {
            'charging_mode': self._map_charging_mode(output[0]),
            'power_saving_priority': output[1],
            'recommended_power_allocation': output[2],
            'energy_alert_level': output[3]
        }
```

## üîÑ –ú–µ—Ç–æ–¥–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è

### 1. Q-Learning –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π

```python
class QLearningAgent:
    """
    Q-Learning –∞–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π
    
    –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –í QIKI:
    - –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–æ–≤ —Ä–∞–±–æ—Ç—ã –ø–æ–¥—Å–∏—Å—Ç–µ–º
    - –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π
    - –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –∏–∑–º–µ–Ω—è—é—â–∏–º—Å—è —É—Å–ª–æ–≤–∏—è–º
    """
    
    def __init__(self, state_size, action_size, learning_rate=0.1, 
                 discount_factor=0.95, epsilon=1.0):
        self.q_table = {}  # –¢–∞–±–ª–∏—Ü–∞ Q-–∑–Ω–∞—á–µ–Ω–∏–π
        self.learning_rate = learning_rate      # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        self.discount_factor = discount_factor  # –§–∞–∫—Ç–æ—Ä –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.epsilon = epsilon                  # –ü–∞—Ä–∞–º–µ—Ç—Ä –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        self.epsilon_decay = 0.995             # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        self.epsilon_min = 0.01                # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
        
    def get_action(self, state):
        """
        Epsilon-greedy —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π
        
        –ü–†–ê–í–ò–õ–û: –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∑–Ω–∞–Ω–∏–π
        - epsilon –≤—ã—Å–æ–∫–∏–π = –±–æ–ª—å—à–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (—Å–ª—É—á–∞–π–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è)
        - epsilon –Ω–∏–∑–∫–∏–π = –±–æ–ª—å—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–∂–∞–¥–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è)
        """
        state_key = self._state_to_key(state)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Q-–∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –Ω–æ–≤–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if state_key not in self.q_table:
            self.q_table[state_key] = [0.0] * self.action_size
        
        # Epsilon-greedy –≤—ã–±–æ—Ä
        if random.random() < self.epsilon:
            return random.randint(0, self.action_size - 1)  # –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
        else:
            return np.argmax(self.q_table[state_key])       # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    
    def update_q_value(self, state, action, reward, next_state):
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Q-–∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ –ë–µ–ª–ª–º–∞–Ω–∞
        
        Q(s,a) = Q(s,a) + Œ±[r + Œ≥*max(Q(s',a')) - Q(s,a)]
        
        –≥–¥–µ:
        Œ± - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        r - –Ω–∞–≥—Ä–∞–¥–∞
        Œ≥ - —Ñ–∞–∫—Ç–æ—Ä –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        state_key = self._state_to_key(state)
        next_state_key = self._state_to_key(next_state)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, –µ—Å–ª–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–æ–≤—ã–µ
        if state_key not in self.q_table:
            self.q_table[state_key] = [0.0] * self.action_size
        if next_state_key not in self.q_table:
            self.q_table[next_state_key] = [0.0] * self.action_size
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Q-–∑–Ω–∞—á–µ–Ω–∏—è
        current_q = self.q_table[state_key][action]
        max_next_q = max(self.q_table[next_state_key])
        
        new_q = current_q + self.learning_rate * (
            reward + self.discount_factor * max_next_q - current_q
        )
        
        self.q_table[state_key][action] = new_q
        
        # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
```

### 2. –°–∏—Å—Ç–µ–º–∞ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π

```python
class RewardSystem:
    """
    –°–∏—Å—Ç–µ–º–∞ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
    
    –ü–†–ò–ù–¶–ò–ü–´ –í–û–ó–ù–ê–ì–†–ê–ñ–î–ï–ù–ò–ô:
    - –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–µ–π
    - –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
    - –ì—Ä–∞–¥—É–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π
    """
    
    @staticmethod
    def calculate_power_reward(power_state, action_taken, outcome):
        """
        –†–∞—Å—á–µ—Ç –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        
        –ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
        +10: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑—Ä—è–¥–∞
        +5:  –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–æ–ª–Ω–µ—á–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏
        +3:  –ü–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–∞—Ä—è–¥–∞
        -10: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑—Ä—è–¥ –±–∞—Ç–∞—Ä–µ–∏
        -5:  –ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ
        -3:  –ü–µ—Ä–µ–≥—Ä–µ–≤ –±–∞—Ç–∞—Ä–µ–∏
        """
        reward = 0
        
        # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ —É—Ä–æ–≤–µ–Ω—å –∑–∞—Ä—è–¥–∞
        if power_state.battery_charge > 0.8:
            reward += 3  # –•–æ—Ä–æ—à–∏–π —É—Ä–æ–≤–µ–Ω—å –∑–∞—Ä—è–¥–∞
        elif power_state.battery_charge < 0.15:
            reward -= 10  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑—Ä—è–¥
        elif power_state.battery_charge < 0.3:
            reward -= 3   # –ù–∏–∑–∫–∏–π –∑–∞—Ä—è–¥
        
        # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ä–µ–∂–∏–º
        if 15 <= power_state.battery_temp <= 25:
            reward += 2  # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
        elif power_state.battery_temp > 40:
            reward -= 5  # –ü–µ—Ä–µ–≥—Ä–µ–≤
        
        # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞—Ä—è–¥–∫–∏
        if outcome.get('charging_efficiency', 0) > 0.8:
            reward += 5
        
        return reward
    
    @staticmethod
    def calculate_thermal_reward(thermal_state, action_taken, outcome):
        """
        –†–∞—Å—á–µ—Ç –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –¥–ª—è —Ç–µ—Ä–º–∞–ª—å–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        """
        reward = 0
        
        # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
        for zone_temp in thermal_state.zone_temperatures:
            if -10 <= zone_temp <= 40:
                reward += 1  # –ù–æ—Ä–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
            elif zone_temp > 50:
                reward -= 8  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–≥—Ä–µ–≤
            elif zone_temp < -20:
                reward -= 5  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ
        
        # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ö–ª–∞–∂–¥–µ–Ω–∏—è
        cooling_efficiency = outcome.get('cooling_efficiency', 0)
        if cooling_efficiency > 0.7:
            reward += 3
        
        return reward
```

## üõ†Ô∏è –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ò–ò-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

### 1. –ü—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞

```
–°–æ–∑–¥–∞–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ò–ò-–∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã QIKI —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:

–ù–ê–ó–í–ê–ù–ò–ï –ê–ì–ï–ù–¢–ê: [NavigationAgent/SensorAgent/CommunicationAgent]

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï: 
- –°–ø–∏—Å–æ–∫ –∏–∑ [X] –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∫–∞–∂–¥–æ–≥–æ
- –î–∏–∞–ø–∞–∑–æ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏–π –∏ —Å–ø–æ—Å–æ–±—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

–í–´–•–û–î–ù–´–ï –†–ï–®–ï–ù–ò–Ø:
- [Y] –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π/—Ä–µ–∂–∏–º–æ–≤
- –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π
- –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –≤—ã—Ö–æ–¥–æ–≤

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ù–ï–ô–†–û–°–ï–¢–ò:
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤: [2-4]
- –†–∞–∑–º–µ—Ä—ã —Å–ª–æ–µ–≤: [—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã]
- –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è

–°–ò–°–¢–ï–ú–ê –í–û–ó–ù–ê–ì–†–ê–ñ–î–ï–ù–ò–ô:
- –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã –∑–∞ [–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è]
- –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–≥—Ä–∞–¥—ã –∑–∞ [–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è]
- –ß–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–≥—Ä–∞–¥

–ú–ï–¢–†–ò–ö–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:
- –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
- –°–ø–æ—Å–æ–±—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
- –ß–∞—Å—Ç–æ—Ç–∞ –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

–ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã BaseAdvancedAgent –∏ —Å–ª–µ–¥—É–π –ø—Ä–∏–Ω—Ü–∏–ø–∞–º QIKI.
```

### 2. –ü—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏

```
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∞–≥–µ–Ω—Ç–∞ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è:

–ü–†–û–ë–õ–ï–ú–ê: [–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–±–ª—é–¥–∞–µ–º–æ–π –ø—Ä–æ–±–ª–µ–º—ã]

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï: [–ø—Ä–∏–º–µ—Ä—ã –≤—Ö–æ–¥–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤]
–í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï: [–ø—Ä–∏–º–µ—Ä—ã –≤—ã—Ö–æ–¥–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤]
–û–ñ–ò–î–ê–ï–ú–û–ï –ü–û–í–ï–î–ï–ù–ò–ï: [—á—Ç–æ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å]

–ú–ï–¢–†–ò–ö–ò –û–ë–£–ß–ï–ù–ò–Ø:
- Loss: [—Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è]
- Accuracy: [—Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è]
- –°—Ö–æ–¥–∏–º–æ—Å—Ç—å: [—Å–∫–æ—Ä–æ—Å—Ç—å/–ø—Ä–æ–±–ª–µ–º—ã]

–í–û–ó–ú–û–ñ–ù–´–ï –ü–†–ò–ß–ò–ù–´:
1. –ü—Ä–æ–±–ª–µ–º—ã —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π —Å–µ—Ç–∏
2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
3. –ù–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
4. –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–∏—Å—Ç–µ–º–æ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π
5. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö

–ü—Ä–µ–¥–ª–æ–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–¥–µ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º.
```

### 3. –ü—Ä–æ–º–ø—Ç –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```
–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π –ò–ò-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Å–∏—Å—Ç–µ–º—ã QIKI –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Termux:

–¢–ï–ö–£–©–ò–ô –ö–û–î: [–∫–æ–¥ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞]

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –°–†–ï–î–´:
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å
- –°–ª–∞–±—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ GPU
- –ë–∞—Ç–∞—Ä–µ–π–Ω–æ–µ –ø–∏—Ç–∞–Ω–∏–µ

–¶–ï–õ–ò –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
1. –£–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
2. –£—Å–∫–æ—Ä–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
3. –°–Ω–∏–∂–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏

–ú–ï–¢–û–î–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
- –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
- –ü—Ä—É–Ω–∏–Ω–≥ –Ω–µ–π—Ä–æ–Ω–æ–≤
- –£–ø—Ä–æ—â–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- –õ–µ–Ω–∏–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è

–ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
```

## üìä –ú–µ—Ç–æ–¥–∏–∫–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

### 1. –Æ–Ω–∏—Ç-—Ç–µ—Å—Ç—ã –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π

```python
class NeuralNetworkTests:
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    
    –ü–†–ê–í–ò–õ–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:
    - –ö–∞–∂–¥–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    """
    
    @staticmethod
    def test_activation_functions():
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        test_values = [-1000, -10, -1, 0, 1, 10, 1000]
        
        for val in test_values:
            # ReLU –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å max(0, x)
            relu_result = ActivationFunctions.relu(val)
            assert relu_result >= 0, f"ReLU failed for {val}"
            
            # Sigmoid –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –≤ (0, 1)
            sigmoid_result = ActivationFunctions.sigmoid(val)
            assert 0 < sigmoid_result < 1, f"Sigmoid failed for {val}"
    
    @staticmethod
    def test_agent_consistency():
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ—à–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–∞"""
        agent = IntelligentPowerAgent()
        test_state = [0.5] * 12  # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        # –û–¥–∏–Ω–∞–∫–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –¥–∞–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è
        decision1 = agent.make_decision(test_state)
        decision2 = agent.make_decision(test_state)
        
        # –ü—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–Ω–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ (epsilon=0)
        agent.epsilon = 0
        assert decision1 == decision2, "Inconsistent decisions for same state"
    
    @staticmethod
    def test_learning_convergence():
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è"""
        agent = QLearningAgent(state_size=4, action_size=3)
        
        # –ü—Ä–æ—Å—Ç–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π –æ–±—É—á–µ–Ω–∏—è
        state = [0.5, 0.3, 0.8, 0.2]
        best_action = 1  # –ò–∑–≤–µ—Å—Ç–Ω–æ–µ –ª—É—á—à–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        
        # –û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞–≥—Ä–∞–¥–æ–π –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
        for _ in range(1000):
            action = agent.get_action(state)
            reward = 10 if action == best_action else -1
            next_state = state  # –°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è
            agent.update_q_value(state, action, reward, next_state)
        
        # –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –≤—ã–±–∏—Ä–∞—Ç—å –ª—É—á—à–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        agent.epsilon = 0  # –û—Ç–∫–ª—é—á–∏—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
        final_action = agent.get_action(state)
        assert final_action == best_action, "Agent didn't learn optimal action"
```

### 2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã

```python
class IntegrationTests:
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
    """
    
    @staticmethod
    def test_agent_coordination():
        """
        –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏
        
        –°–¶–ï–ù–ê–†–ò–ô: –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π –∫—Ä–∏–∑–∏—Å
        - PowerAgent –¥–æ–ª–∂–µ–Ω –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ
        - ThermalAgent –¥–æ–ª–∂–µ–Ω —Å–Ω–∏–∑–∏—Ç—å –æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ
        - –í—Å–µ –∞–≥–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã —Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å —Å–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è
        """
        power_agent = IntelligentPowerAgent()
        thermal_agent = IntelligentThermalAgent()
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏
        crisis_state = {
            'battery_charge': 0.12,  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å
            'system_load': 0.8,      # –í—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
            'temperature': 35        # –ü–æ–≤—ã—à–µ–Ω–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
        }
        
        power_decision = power_agent.make_decision(crisis_state)
        thermal_decision = thermal_agent.make_decision(crisis_state)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏
        assert power_decision['power_saving_priority'] > 0.8
        assert thermal_decision['cooling_reduction'] > 0.5
```

## üîß –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ

### 1. –ü—Ä–∏–Ω—Ü–∏–ø—ã –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏

```python
# –ü–†–ê–í–ò–õ–¨–ù–û: –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
class AgentManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏
    
    –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê:
    - –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    - –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏
    """
    
    def __init__(self):
        self.agents = {}
        self.coordination_rules = []
    
    def register_agent(self, name, agent):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
        self.agents[name] = agent
    
    def coordinate_decisions(self, global_state):
        """–ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏–π –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
        decisions = {}
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏–π –æ—Ç –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
        for name, agent in self.agents.items():
            agent_state = self._extract_agent_state(global_state, name)
            decisions[name] = agent.make_decision(agent_state)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏
        coordinated_decisions = self._apply_coordination_rules(decisions)
        
        return coordinated_decisions

# –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û: –ú–æ–Ω–æ–ª–∏—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
class MonolithicAI:
    """
    –ü–õ–û–•–û–ô –ü–†–ò–ú–ï–†: –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –æ–¥–Ω–æ–º –∫–ª–∞—Å—Å–µ
    
    –ü–†–û–ë–õ–ï–ú–´:
    - –°–ª–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å
    - –°–ª–æ–∂–Ω–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å
    - –ù–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø–∞ –µ–¥–∏–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
    """
    def handle_everything(self, state):
        # –°–æ—Ç–Ω–∏ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞ –¥–ª—è –≤—Å–µ—Ö –ø–æ–¥—Å–∏—Å—Ç–µ–º
        pass
```

### 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å

```python
class RobustAgent(BaseAdvancedAgent):
    """
    –ê–≥–µ–Ω—Ç —Å –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å—é –∫ –æ—à–∏–±–∫–∞–º
    
    –ü–†–ò–ù–¶–ò–ü–´ –ù–ê–î–ï–ñ–ù–û–°–¢–ò:
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
    - Fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫
    """
    
    def make_decision(self, state):
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            validated_state = self._validate_input(state)
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
            decision = super().make_decision(validated_state)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            validated_decision = self._validate_output(decision)
            
            return validated_decision
            
        except Exception as e:
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
            self.logger.error(f"Decision making failed: {e}")
            
            # Fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
            return self._get_safe_fallback_decision(state)
    
    def _validate_input(self, state):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if not isinstance(state, (list, np.ndarray)):
            raise ValueError("State must be a list or numpy array")
        
        if len(state) != self.expected_input_size:
            raise ValueError(f"Expected {self.expected_input_size} inputs, got {len(state)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏
        state = np.array(state)
        if np.any(np.isnan(state)) or np.any(np.isinf(state)):
            self.logger.warning("Invalid values detected in state, using last known good state")
            state = self.last_known_good_state
        
        return state
    
    def _get_safe_fallback_decision(self, state):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏"""
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
        return {
            'action': 'maintain_current_state',
            'confidence': 0.1,
            'reasoning': 'fallback_due_to_error'
        }
```

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### 1. –°–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤

```python
class AgentMetrics:
    """
    –°–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤
    """
    
    def __init__(self, agent_name):
        self.agent_name = agent_name
        self.metrics = {
            'decisions_made': 0,
            'successful_decisions': 0,
            'total_reward': 0.0,
            'average_confidence': 0.0,
            'learning_rate': 0.0,
            'response_time': [],
            'error_count': 0
        }
    
    def record_decision(self, decision_time, success, reward, confidence):
        """–ó–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫ —Ä–µ—à–µ–Ω–∏—è"""
        self.metrics['decisions_made'] += 1
        if success:
            self.metrics['successful_decisions'] += 1
        self.metrics['total_reward'] += reward
        self.metrics['response_time'].append(decision_time)
        
        # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        self.metrics['average_confidence'] = (
            self.metrics['average_confidence'] * 0.9 + confidence * 0.1
        )
    
    def get_performance_report(self):
        """–û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if self.metrics['decisions_made'] == 0:
            return "No decisions made yet"
        
        success_rate = (self.metrics['successful_decisions'] / 
                       self.metrics['decisions_made'] * 100)
        avg_reward = (self.metrics['total_reward'] / 
                     self.metrics['decisions_made'])
        avg_response_time = (sum(self.metrics['response_time']) / 
                           len(self.metrics['response_time']))
        
        return f"""
        Agent: {self.agent_name}
        Success Rate: {success_rate:.2f}%
        Average Reward: {avg_reward:.3f}
        Average Confidence: {self.metrics['average_confidence']:.3f}
        Response Time: {avg_response_time:.3f}ms
        Errors: {self.metrics['error_count']}
        """
```

–≠—Ç–∞ –º–µ—Ç–æ–¥–∏–∫–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –Ω–∞–¥–µ–∂–Ω—ã—Ö –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –ò–ò-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã QIKI —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –º–æ–±–∏–ª—å–Ω–æ–π —Å—Ä–µ–¥—ã.